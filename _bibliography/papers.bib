---
---

@string{aps = {American Physical Society,}}

@book{einstein1956investigations,
  bibtex_show={true},
  title={Investigations on the Theory of the Brownian Movement},
  author={Einstein, Albert},
  year={1956},
  publisher={Courier Corporation},
  preview={brownian-motion.gif}
}

@article{einstein1950meaning,
  abbr={AJP},
  bibtex_show={true},
  title={The meaning of relativity},
  author={Einstein, Albert and Taub, AH},
  journal={American Journal of Physics},
  volume={18},
  number={6},
  pages={403--404},
  year={1950},
  publisher={American Association of Physics Teachers}
}

@article{PhysRev.47.777,
  abbr={PhysRev},
  title={Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?},
  author={Einstein, A. and Podolsky, B. and Rosen, N.},
  abstract={In a complete theory there is an element corresponding to each element of reality. A sufficient condition for the reality of a physical quantity is the possibility of predicting it with certainty, without disturbing the system. In quantum mechanics in the case of two physical quantities described by non-commuting operators, the knowledge of one precludes the knowledge of the other. Then either (1) the description of reality given by the wave function in quantum mechanics is not complete or (2) these two quantities cannot have simultaneous reality. Consideration of the problem of making predictions concerning a system on the basis of measurements made on another system that had previously interacted with it leads to the result that if (1) is false then (2) is also false. One is thus led to conclude that the description of reality as given by a wave function is not complete.},
  journal={Phys. Rev.},
  volume={47},
  issue={10},
  pages={777--780},
  numpages={0},
  year={1935},
  month={May},
  publisher=aps,
  doi={10.1103/PhysRev.47.777},
  url={http://link.aps.org/doi/10.1103/PhysRev.47.777},
  html={https://journals.aps.org/pr/abstract/10.1103/PhysRev.47.777},
  pdf={example_pdf.pdf},
  altmetric={248277},
  dimensions={true},
  google_scholar_id={qyhmnyLat1gC}
}

@article{einstein1905molekularkinetischen,
  title={{\"U}ber die von der molekularkinetischen Theorie der W{\"a}rme geforderte Bewegung von in ruhenden Fl{\"u}ssigkeiten suspendierten Teilchen},
  author={Einstein, A.},
  journal={Annalen der physik},
  volume={322},
  number={8},
  pages={549--560},
  year={1905},
  publisher={Wiley Online Library}
}

@article{einstein1905movement,
  abbr={Ann. Phys.},
  title={Un the movement of small particles suspended in statiunary liquids required by the molecular-kinetic theory 0f heat},
  author={Einstein, A.},
  journal={Ann. Phys.},
  volume={17},
  pages={549--560},
  year={1905}
}

@article{einstein1905electrodynamics,
  title={On the electrodynamics of moving bodies},
  author={Einstein, A.},
  year={1905}
}

@book{przibram1967letters,
  bibtex_show={true},
  title={Letters on wave mechanics},
  author={Einstein, Albert and Schr√∂dinger, Erwin and Planck, Max and Lorentz, Hendrik Antoon and Przibram, Karl},
  year={1967},
  publisher={Vision},
  preview={wave-mechanics.gif}
}

@inproceedings{gaoFairneuronImprovingDeep2022,
  abbr = {ICSE},
  title = {Fairneuron: Improving Deep Neural Network Fairness with Adversary Games on Selective Neurons},
  shorttitle = {Fairneuron},
  booktitle = {2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)},
  author = {Gao, Xuanqi and Zhai, Juan and Ma, Shiqing and Shen, Chao and Chen, Yufei and Wang, Qian},
  year = {2022},
  pages = {921--933},
  issn = {1558-1225},
  code = {https://github.com/Antimony5292/FairNeuron},
  video = {https://youtu.be/pAe4os3JjA0},
  arxiv = {https://arxiv.org/pdf/2204.02567},
  doi = {10.1145/3510003.3510087},
  abstract = {With Deep Neural Network (DNN) being integrated into a growing number of critical systems with far-reaching impacts on society, there are increasing concerns on their ethical performance, such as fairness. Unfortunately, model fairness and accuracy in many cases are contradictory goals to optimize during model training. To solve this issue, there has been a number of works trying to improve model fairness by formalizing an adversarial game in the model level. This approach introduces an adversary that evaluates the fairness of a model besides its prediction accuracy on the main task, and performs joint-optimization to achieve a balanced result. In this paper, we noticed that when performing backward prop-agation based training, such contradictory phenomenon are also observable on individual neuron level. Based on this observation, we propose Fairneuron, a Dnn model automatic repairing tool, to mitigate fairness concerns and balance the accuracy-fairness trade-off without introducing another model. It works on detecting neurons with contradictory optimization directions from accuracy and fairness training goals, and achieving a trade-off by selective dropout. Comparing with state-of-the-art methods, our approach is lightweight, scaling to large models and more efficient. Our eval-uation on three datasets shows that Fairneuron can effectively improve all models' fairness while maintaining a stable utility.},
  eventtitle = {2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)},
  keywords = {Deep learning,fairness,Games,neural networks,Neural networks,Neurons,path analysis,Predictive models,Search problems,Training},
  preview={ICSE22.gif},
  selected = {true}
}

@inproceedings{gaoCILIATEFairerClassBased2023,
  abbr = {ISSTA},
  title = {CILIATE: Towards Fairer Class-Based Incremental Learning by Dataset and Training Refinement},
  shorttitle = {CILIATE},
  booktitle = {Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis},
  author = {Gao, Xuanqi and Zhai, Juan and Ma, Shiqing and Shen, Chao and Chen, Yufei and Wang, Shiwei},
  year = {2023},
  series = {ISSTA 2023},
  pages = {475--487},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/3597926.3598071},
  code = {https://github.com/Antimony5292/CILIATE},
  url = {https://dl.acm.org/doi/10.1145/3597926.3598071},
  arxiv = {https://arxiv.org/pdf/2304.04222},
  urldate = {2023-07-23},
  abstract = {Due to the model aging problem, Deep Neural Networks (DNNs) need updates to adjust them to new data distributions. The common practice leverages incremental learning (IL), e.g., Class-based Incremental Learning (CIL) that updates output labels, to update the model with new data and a limited number of old data. This avoids heavyweight training (from scratch) using conventional methods and saves storage space by reducing the number of old data to store. But it also leads to poor performance in fairness. In this paper, we show that CIL suffers both dataset and algorithm bias problems, and existing solutions can only partially solve the problem. We propose a novel framework, CILIATE, that fixes both dataset and algorithm bias in CIL. It features a novel differential analysis guided dataset and training refinement process that identifies unique and important samples overlooked by existing CIL and enforces the model to learn from them. Through this process, CILIATE improves the fairness of CIL by 17.03\%, 22.46\%, and 31.79\% compared to state-of-the-art methods, iCaRL, BiC, and WA, respectively, based on our evaluation on three popular datasets and widely used ResNet models. Our code is available at https://github.com/Antimony5292/CILIATE.},
  isbn = {9798400702211},
  keywords = {fairness,incremental learning,neural network},
  preview={brownian-motion.gif},
  selected = {true}
}